\chapter{État de l'art}

Ce chapitre présente le domaine des systèmes de gestion de flux de travail scientifique, l'approche algébrique adoptée par ces systèmes, et les défis rencontrés dans la parallélisation de ces flux. Il introduit également  la programmation GPGPU comme une solution intéressante dans le parallélisme des flux de travail scientifiques. 
%\textbf{Les systèmes de gestion de gestion de flux de travail scientifique}dans un premier temps 

\section{Les systèmes de gestion de flux de travail scientifique}
%Le concept de
%Un gestion de flux de travail scientifique c'est une abstraction pour modéliser et simuler les expériences scientifiques, 

 %manipuler ces gestion de flux de travail (stockage, interrogation, visualisation etc.) %les systèmes des gestion de flux de travail scientifiques sont utilisés pour la gestion des expériences scientifiques où de nombreuses tâches bioinformatiques sont chaînées les unes aux autres,un grand nombre d'outils disponibles pour manipuler ces gestion de flux de travail (stockage, interrogation, visualisation etc.) existe aujourd’hui. 
%ces systèmes représentent les gestion de flux de travail sous la forme d’un graphe pour optimiser le traitement/stockage des informations. 

%On retrouve ainsi 

Le progrès massif dans les différents domaines scientifiques requiert des analyses plus complexes et raffinées sur les expériences scientifiques. Ces expériences à grande échelle sont généralement composées de plusieurs modèles de calcul mathématiques et informatiques. Ils peuvent impliquer l'exécution des simulations sur plusieurs pas de temps, le \textit{fine-tuning} sur un grand ensemble de paramètres. Afin d’assurer une bonne gestion de ces expériences il faut garantir leurs efficacité, cohérence, et reproductibilité \cite{cal}. C’est une tâche très importante mais aussi compliquée compte tenu de la nécessité d'indiquer la provenance des données. Dans le but d'accorder une approche systématique pour modéliser et exécuter de telles expériences, de nombreux domaines scientifiques (comme les services d'informations, et l'analyse de signal) utilisent les systèmes de gestion de flux de travail scientifique (SWfMS) \cite{cal}. Les SWfMS sont des outils pour modéliser et orchestrer l'exécution des flux de travail scientifique. Ils permettent aux utilisateurs de spécifier un flux de travail composé par des activités (programmes informatiques) et par le flux de données entre ces activitées. Cela permet d'enchaîner et de contrôler des différentes tâches pour réaliser un traitement complexe \cite{oga11}. 

% l'exécution en executant des requetes sur la base de données 
%Dans les infrastructures actuelles distribuées, avec des ressources hétérogènes, les systèmes des gestion de flux de travail scientifiques deviennent de plus en plus primordiaux  \cite{cal}. Ils offrent un traitement parallèle et distribué en utilisant soit des ressources informatiques locales, soit un environnement réparti tels que les \textit{clusters}, les grilles ou les \textit{clouds}. 

Dans le cadre de ce stage on s'appuie sur Chiron comme un système de gestion de flux de travail. Chiron (voir Annexe \ref{chiron}) a été crée à l'institue COPPE\footnote{COPPE – Instituto Alberto Luiz Coimbra de Pós-Graduação e Pesquisa de Engenharia.} de l'Université Fédérale de Rio de Janeiro (UFRJ)  avec l'équipe de recherche de Marta Matosso au laboratoire NACAD.
\vspace{0.5cm}
\section[La provenance des données]{La provenance des données dans les systèmes de gestion du flux de travail scientifique  }
L'un des principaux avantages des systèmes de gestion du flux de travail provient de l'enregistrement de la provenance des données. On définit la provenance des données comme des informations qui permettent de déterminer l'historique de dérivation d'un produit de données, à partir de ça source d'origine \cite{sim}. Les deux caractéristiques importantes de la provenance d'un produit de données sont d'une part le produit ancêtre de données à partir de lequel ce produit de données a évolué, et d'autre part le processus de transformation de ce produit ancêtre de données, éventuellement par le biais du flux de travail, qui a aidé à obtenir ce produit de données. Les informations de provenance peuvent être collectées par un modèle orienté processus, où les processus sont les principales entités pour lesquelles la provenance est recueillie, et la provenance des données est déterminée par l'inspection d'entrée et de sortie des produits de données de ces processus.
Si les informations de provenance sont disponibles, ils donnent la possibilité aux utilisateurs d'analyser les résultats de flux de travail, et de décider la dépendance et l'ordonnancement entre les activités de ce flux.
Des requêtes soumises sur les données de provenance peuvent alimenter automatiquement les ensembles de données d'entrée pour un flux de travail en temps d'exécution. L'historique de dérivation des ensembles de données décrit comment le flux de travail a été spécifié et exécuté. Il peut être utilisé pour répliquer les données sur un autre site, ou le mettre à jour si un ensemble de données est périmé en raison de modifications apportées à ses ancêtres.
\vspace{0.5cm}
\section[L'approche algébrique]{L'approche algébrique pour l'exécution parallèle de flux de travail }

%SWfMS tels que Chiron \pageref{chiron} adopte la sémantique des opérateurs algébriques.
 Considérant un flux des tâches avec une dépendance de données entre ces tâches, le modèle d'exécution d'un flux de travail est étroitement couplé à ces spécification \cite{san}. Ce couplage réduit la possibilité d'améliorer les stratégies d'exécution par le système de gestion et par conséquence les améliorations doivent être codées manuellement. Pour répondre à la question de l'optmisation de l'exécution parallèle d'un flux de travail une approche a été proposée dans \cite{oga11}. Elle consiste à abstraire la gestion d'un flux de travail scientifique sous une approche algébrique, inspirée par l'algèbre relationnelle pour les bases de données. Cela fournit un modèle uniform de données qui exprime toutes les données d'une expérience par des relations, chaque combinaison de valeurs des paramètres compose un n-uplet, et les activités de gestion de flux de travail consomment et produisent des n-uplets. Cette abstraction a amélioré la conception et la réutilisation du flux de travail, lorsque les activités sont représentées comme des opérateurs algébriques. Les moteurs de gestion de flux de travail peuvent en outre jouer avec des expressions algébriques équivalentes. Ainsi, les SWfMS identifient la façon dont les données sont structurées et ce qu'il faut attendre de chaque activité, en termes de production et de consommation des données. De cette façon, il est possible d'effectuer des optimisations algébriques et d'adopter des stratégies de distribution intelligentes. 
 

%\paragraph{Chiron}
%(voir Annexe \ref{chiron}) 
%Chiron est un système de gestion de flux de travail de calculs numériques (\textit{scientifique workflow management system}),  il exécute ces simulations comme une chaîne d'activités (programmes) et un flux de données (\textit{dataflow}) sur ces activités. Ce système fournit la gestion des simulations scientifiques, leur exécution parallèle tout en enregistrant la provenance des données. Chiron implémente l'approche algébrique dans un style MapReduce. L'utilisation de MapReduce comme approche de programmation permet aux scientifiques de programmer d'un façon plus simple la procédure du calcul en cachant le parallélisme, qui peut être complexe à gérer \cite{oga13}.

%ratio  Ainsi, l'algèbre soutient naturellement la nature exploratoire des simulations informatiques.
% Les opérateurs excluent les activités de flux de travail en établissant une consommation de données et les critères de production pour chaque activité.
\vspace{0.5cm}
\section[Le parallélisme]{Le parallélisme dans les systèmes de gestion du flux de travail scientifique}
L'ampleur des données produites dans les nombreux domaines scientifiques augmente à un rythme exponentiel, et le progrès de capacité de stockage, de bande passante du réseau, et de puissance de traitement est souvent dépassé. Outre les progrès algorithmiques, la manière canonique pour faire face à l'augmentation des volumes de données est le parallélisme. Cela se reflète dans le développement de l'exécution parallèle des threads sur des puces simples. Ainsi que le développement des infrastructures qui combinent plusieurs machines à des clusters, des grids et des clouds.
%Alors que plusieurs SWfMS comme Dagman et Pegasus (voir Annexe )ont été conçus avec le calcul parallèle sur les ressources partagées, ils fournissent rarement la prise en charge des multicoeur et sont généralement difficile à mettre en place et à utiliser par les scientifiques du domaine. systèmes plus récents comme Taverna mettent davantage l'accent sur la convivialité, mais ne fournissent que des moyens limités vers parallélisation et l'utilisation des ressources informatiques distribuées.
Les réalisations des exécution des flux de travail parallèle sont généralement désignés afin de fonctionner dans ces environnement de calcul particulier.% Généralement, on peut différencier entre trois paramètres: cluster, grids, et clouds.

Une grille informatique (en anglais, grid) est une infrastructure virtuelle constituée d'un ensemble de ressources informatiques potentiellement partagées, distribuées, hétérogènes, délocalisées et autonomes. %Un grid de calcul est un nouveau paradigme de l'informatique distribué dans lequel les ressources de calcul pourraient être hétérogènes et géographiquement éloignés.
Cette infrastructure est qualifiée de virtuelle car les relations entre les entités qui la composent n'existent pas sur le plan matériel mais d'un point de vue logique. L'idée d'un grid est de relier les ressources informatiques afin de résoudre des problèmes de calcul exigeants sans avoir besoin d'un super-ordinateur. Plusieurs SWfMS, tels que Pegasus \cite{pegasus} ou Condor Dagman \cite{condor}, ont été développés pour utiliser les grids pour l'exécution parallèle des flux de travail de calcul intensif.
L’informatique en nuage (en anglais, cloud computing) %décrit une forme de création plus récente de l'informatique distribuée, 
est l'exploitation de la puissance de calcul ou de stockage de serveurs informatiques distants par l'intermédiaire d'un réseau. Ces ressources de calcul et de stockage sont louables sur demande et sur Internet. Le rendement réel des machines virtuelles louées varie considérablement en fonction de la configuration du matériel et de l'utilisation des ressources sous-jacentes partagées  par d'autres utilisateurs. Dans les environnements de grids et de clouds, le transfert important sur des zones étendues des données et les retards dans l'instanciation de grandes quantités des tâches, conduit à une dégradation de performance. 
Un cluster de calcul est un ensemble d'ordinateurs étroitement connectés et fonctionnants comme un système unique. Un nombre toujours croissant de cœurs par processeur et processeurs par cluster ont conduit à un fort potentiel de parallélisation. Puisque les ressources de calcul en clusters sont étroitement couplés, la localité de données est moins problématique par rapport à des environnements distribués, tels que les grids et les clouds. Les clusters fournissent un environnement plus homogène en termes de performances du processeur et de la latence / bande passante entre les n{\oe}uds de calcul. Cependant, l'évolutivité des clusters est limitée et les coûts initiaux d'investissement sont assez élevés, ce qui est problématique.
 %Considérant un flux des tâches avec une dépendance de données entre ces tâches, le modèle d'exécution d'un flux de travail est étroitement couplé à ces spécification \cite{san}. Ce couplage réduit la possibilité d'améliorer les stratégies d'exécution par le système de gestion et par conséquence les améliorations doivent être codées manuellement. 
De toute évidence, l'exécution des flux de travail scientifique présente des défis différents en fonction de l'infrastructure informatique sous-jacente \cite{bux}. 
Les spécifications pour l'exécution en parallèle d'un flux de travail scientifique sont généralement définies avec un langage de script. Ce langage est traitée par un moteur de flux de travail qui génère un plan correspondant pour l'exécution parallèle. Ce plan est une mise en correspondance entre l'architecture parallèle des matériels et la planification des tâches correspondants. Développeurs de flux de travail doivent décider l'ordre, les dépendances et les stratégies de parallélisation. Ces décisions resserrent les possibilités de parallélisation, et peuvent donner à manquer de grandes opportunités d'optimisation.
 Le but de ce stage est d'expérimenter l'accélération GPU comme une nouvelle approche de parallélisme dans le domaine de gestion de flux de travail scientifique. Actuellement, le seul SWfMS qui est en mesure de tirer parti des accélérateurs tels que GPGPU est Swift \cite{kri}. Néanmoins, %, pour tirer profit des GPGPU lors de l'exécution en parallèle, de nouveaux scripts sont nécessaires ou une mapping manuel doit être fait.
La définition de flux de travail dans Swift est fortement couplée à la procédure d'exécution du flux de travail. Et la provenance de données dans Swift est basée sur l'extraction des données à partir des fichiers de logs, de ce fait, le scientifique peut explorer la base de données de provenance uniquement lorsque l'exécution est terminée.
% les coûts initiaux d'acquisition sont assez élevés, ce qui est problématique.
			
		
	

\vspace{0.5cm}
\section{La programmation GPGPU}
 
Les cartes graphiques (GPU) sont des dispositifs performants et spécialisés dotés de nombreuses unités de calcul, dédiés à l'affichage et au traitement 3D. La technologie GPGPU est l'abréviation de \textit{general-purpose computing on graphics processing units}, c'est-à-dire un calcul générique sur un processeur graphique. Cette technologie exploite la puissance de calcul des GPUs pour le traitement massivement parallèle, elle permet d'accélérer les portions de code les plus lourdes en ressources de calcul, en les parallélisant sur de nombreuses unités de calcul, le reste de l'application restant affecté au CPU. La programmation GPGPU offre une accélération très élevée pour un large éventail d'applications scientifiques et commerciales, nettement supérieure à celle offertes par une architecture basée uniquement sur des CPUs \cite{nv}.
Les GPUs offrent une possibilité d'améliorer les exécutions parallèles de flux de travail scientifiques, souvent exprimé avec un grand nombre des tâches de calcul.  % ce qui est très fréquent dans la bio-informatique.
% Explorer dynamiquement les GPUs dans Les tâches concurrentes est une question ouverte, %en particulier dans les flux de travail scientifique exécution parallèle.
Il existe deux outils dédiés à réaliser des calculs généralistes Cuda et OpenCL. Ce sont des outils de très bas niveau d'abstraction, ils demandent de manipuler explicitement de nombreux paramètres matériels. Pour rendre cette t\^ache plus souple et s\^ure, SPOC (voir Annexe \ref{chiron}) est un choix imposé dans le projet. Il consiste à une abstraction haut niveau de la programmation GPGPU. En simplifiant la programmation GPGPU et en autorisant le développement d'optimisations supplémentaires. SPOC nous permet d'atteindre un haut niveau de performance. Il assure aussi la portabilité. Et fournit des squelettes qui peuvent être utilisées pour composer les Kernels \footnote{ Dans la programmation GPU, une fonction définie par l'utilisateur qui tourne sur le GPU est appelé un Kernel.}. Les squelettes sont des constructions algorithmiques basées sur des patrons de conception communs, qui peuvent être paramétrées pour adapter leur comportement. Les squelettes décrivent explicitement les relations entre les kernels et les données. En utilisant cette information, il est possible d'optimiser automatiquement le calcul global \cite{bour14}. Spoc est un outil issue du travail de l'équipe APR du laboratoire LIP6 à l'Université Pierre et Marie Curie. 





%La programmation GPGPU permet d'accélérer les portions de code les plus lourdes en ressources de calcul, en parallélisant les tâches de calcul, le reste de l'application restant affecté au CPU.
 %Les applications s'exécutent ainsi bien plus rapidement \cite{nv}.
%être économes en énergie tout en garantissant une haute performance de calcul grâce à leur capacité de  
 %de calcul de gestion de flux de travail scientifique.
%Technique de programmation visant à l'implantation des applications en exécution sur les cartes graphiques (GPU) au lieu des processeurs centraux (CPU). 
%Technique développée depuis le début des années 2000, où c'est rendu possible l'implantation de programmes sur les adaptateurs graphiques (NVidia, ATI, 3D Labs, ...),

% Enfin, SPOC abstrait les transferts mémoires via l’utilisation de jeux de données spécifiques \cite{tte13}.
%Notre objectif est de construire un environnement d’expérimentation de gestion de flux de travail intégré dans une plateforme 

%Les chercheurs font appel à des supercalculateurs toujours plus rapides en vue d'accélérer le rythme des découvertes et des innovations dans un large éventail de domaines scientifiques

%tourner des applications phénoménalement complexes en temps réel et valide l'utilisation de l'informatique accélérée pour répondre à nos problèmes scientifiques les plus urgents
 
%L'informatique accélérée est l'approche la plus adaptée et la plus réaliste pour parvenir à des niveaux de performance exaflopique dans la décennie à venir." 


%Cette nouvelle fonctionnalité permet aux ingénieurs et aux scientifiques d’accroître les performances de leurs calculs  


%Abstract : Bioinformatics experiments are usually performed using scientific gestion de flux de travail in which tasks are chained together forming very intricate and nested graph structures. Scientific gestion de flux de travail systems have then been developed to guide users in the design and execution of gestion de flux de travail. An advantage of these systems over traditional approaches is their ability to automatically record the provenance (or lineage) of intermediate and final data products generated during gestion de flux de travail execution. The provenance of a data product contains information about how the product was derived, and it is crucial for enabling scientists to easily understand, reproduce, and verify scientific results. For several reasons, the complexity of gestion de flux de travail and gestion de flux de travail execution structures is increasing over time, which has a clear impact on scientific gestion de flux de travail reuse.The global aim of this thesis is to enhance gestion de flux de travail reuse by providing strategies to reduce the complexity of gestion de flux de travail structures while preserving provenance. Two strategies are introduced.First, we propose an approach to rewrite the graph structure of any scientific gestion de flux de travail (classically represented as a directed acyclic graph (DAG)) into a simpler structure, namely, a series-parallel (SP) structure while preserving provenance. SP-graphs are simple and layered, making the main phases of gestion de flux de travail easier to distinguish. Additionally, from a more formal point of view, polynomial-time algorithms for performing complex graph-based operations (e.g., comparing gestion de flux de travail, which is directly related to the problem of subgraph homomorphism) can be designed when gestion de flux de travail have SP-structures while such operations are related to an NP-hard problem for DAG structures without any restriction on their structures. The SPFlow rewriting and provenance-preserving algorithm and its associated tool are thus introduced.Second, we provide a methodology together with a technique able to reduce the redundancy present in gestion de flux de travail (by removing unnecessary occurrences of tasks). More precisely, we detect "anti-patterns", a term broadly used in program design to indicate the use of idiomatic forms that lead to over-complicated design, and which should therefore be avoided. We thus provide the DistillFlow algorithm able to transform a gestion de flux de travail into a distilled semantically-equivalent gestion de flux de travail, which is free or partly free of anti-patterns and has a more concise and simpler structure.The two main approaches of this thesis (namely, SPFlow and DistillFlow) are based on a provenance model that we have introduced to represent the provenance structure of the gestion de flux de travail executions. The notion of provenance-equivalence which determines whether two gestion de flux de travail have the same meaning is also at the center of our work. Our solutions have been systematically tested on large collections of real gestion de flux de travail, especially from the Taverna system. Our approaches are available for use at https://www.lri.fr/~chenj/. 
